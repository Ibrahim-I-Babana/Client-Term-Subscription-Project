{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **CLINT TERM SUBSCRIPTION PROJECT**\n",
    "\n",
    "## **1.0 Business Understanding** ##\n",
    "\n",
    "*The financial sector often relies on targeted marketing strategies to drive customer engagement and maximize returns.* *In this context, direct marketing campaigns play a pivotal role in promoting financial products like term deposits.* *This project leverages data from direct phone call marketing campaigns conducted by a banking institution to predict client subscription to term deposits.* *The dataset includes various demographic, financial, and campaign-specific attributes of clients, along with the final outcome indicating whether a term deposit was subscribed (yes) or not (no).*\n",
    "\n",
    "*Using machine learning, this project aims to build a predictive model that will empower the bank's marketing team to identify potential clients more effectively, reduce campaign costs, and optimize resource allocation by focusing on the most promising leads*\n",
    "\n",
    "## **Objective** ##\n",
    "\n",
    "*The primary objective of this project is to develop a classification model using machine learning to predict whether a client will subscribe to a term deposit (y = yes) or not (y = no) based on the features provided in the dataset. This model will support the marketing team in improving campaign effectiveness by enabling targeted outreach to clients with a higher likelihood of subscription*\n",
    "\n",
    "## **Business Questions** ##\n",
    "\n",
    "*1. Which demographic factors (e.g., age, job, marital status, education) most influence the likelihood of subscribing to a term deposit?*\n",
    "\n",
    "*2. How does prior engagement with the bank (e.g., previous campaigns or contact history) impact a client’s decision to subscribe?*\n",
    "\n",
    "*3. What is the effect of financial indicators (e.g., balance, loan status, housing loan status) on subscription likelihood?*\n",
    "\n",
    "*4. Are there specific time-related patterns (e.g., month or day of contact) that correlate with successful subscriptions?*\n",
    "\n",
    "*5. Can the model help identify high-value clients, enabling the marketing team to prioritize resources effectively?*\n",
    "\n",
    "## **Hypothesis** ##\n",
    "\n",
    "**Null Hypothesis (H₀):**\n",
    "\n",
    "*There is no statistically significant relationship between the features provided (e.g., demographic, financial, and campaign-specific attributes) and the likelihood of a client subscribing to a term deposit.*\n",
    "\n",
    "**Alternate Hypothesis (H₁):**\n",
    "\n",
    "*There is a statistically significant relationship between the features provided (e.g., demographic, financial, and campaign-specific attributes) and the likelihood of a client subscribing to a term deposit.*\n",
    "\n",
    "## **2.0 Data Understanding** ##\n",
    "\n",
    "**2.1: Installing and Importing  Packages**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Installing the required libraries for the notebook to accomodate the codes\n",
    "# pip install pyodbc  \n",
    "# pip install python-dotenv \n",
    "# pip install numpy\n",
    "# pip install matplotlib\n",
    "# pip install seaborn\n",
    "# pip install pandas\n",
    "# pip install currency_converter\n",
    "# pip install forex-python\n",
    "# pip install scipy\n",
    "# pip install forex-python\n",
    "# pip install statsmodels\n",
    "# imbalanced-learn          0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1.1: Importing the required Libraries to work with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing the needed libraries \n",
    "# pandas to clean and manipulate the data\n",
    "# numpy for basic calculation\n",
    "# seaborn and matplolib for visualition \n",
    "\n",
    "# Data manipulation packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import pickle\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# Machine learning Packages\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder , LabelEncoder , OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "\n",
    "#Statistical analysis\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from forex_python.converter import CurrencyRates\n",
    "import re\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ks_2samp\n",
    "import scipy.stats\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "\n",
    "\n",
    "\n",
    "# import the dotenv_values function from the dotenv package      \n",
    "# from dotenv import dotenv_values \n",
    "\n",
    "# Database connection package\n",
    "# import pyodbc\n",
    "\n",
    "# Ignore warnings (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.0 Dataset Understanding** ##\n",
    "\n",
    "**From the information:**\n",
    "\n",
    "**bank-full.csv:** *Main dataset with 45,211 examples and 17 attributes (16 input variables + 1 target variable). Use this dataset for full-scale analysis and modeling.*\n",
    "\n",
    "**bank.csv:** *A 10% subset (4,521 examples) for computationally expensive models or quick testing.*\n",
    "\n",
    "## **Key Observations:** ##\n",
    "\n",
    "**No missing values are present.**\n",
    "\n",
    "**Target variable (y) is binary: \"yes\" or \"no\" (classification problem).**\n",
    "\n",
    "**Contains a mix of:**\n",
    "\n",
    "**Numerical variables: age, balance, duration, campaign, pdays, previous.**\n",
    "\n",
    "**Categorical variables: job, marital, education, etc.**\n",
    "\n",
    "**Binary variables: default, housing, loan**\n",
    "\n",
    "## **2.1 Initial Analysis** ##\n",
    "\n",
    "*Perform a detailed overview of the dataset:*\n",
    "\n",
    "**1. Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the 'bank-full.csv'\n",
    "file_path = r'C:\\Users\\user\\OneDrive\\Desktop\\MY DS CAREER ACCELERATOR\\Client-Term-Subscription-Project\\data\\bank-full.csv'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "bank_full = pd.read_csv(file_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Check Dataset Structure:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows:\n",
    "bank_full.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data types and check for missing values\n",
    "bank_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review basic statistics for numerical variables\n",
    "bank_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insights for Modeling** \n",
    "\n",
    "*Balance and duration exhibit significant variability, which may be important predictors for subscription likelihood.*\n",
    "*Pdays and previous indicate that most clients are new to campaigns, but understanding the role of repeat engagement could be valuable.*\n",
    "*Variability in campaign calls and extremely high maximum values could reflect inefficiencies in targeting strategies*\n",
    "\n",
    "**3. Target Variable Distribution:**\n",
    "\n",
    "*This will help assess if techniques like resampling are needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate class balance for y (target)\n",
    "print(bank_full['y'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "*The class distribution of the target variable y reveals significant class imbalance:*\n",
    "\n",
    "*No (Not Subscribed): 88.30% of the data.*\n",
    "\n",
    "*Yes (Subscribed): 11.70% of the data.*\n",
    "\n",
    "**4. Explore Unique Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical variables\n",
    "for col in ['job', 'marital', 'education', 'contact', 'poutcome']:\n",
    "    print(f\"Unique values in {col}: {bank_full[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Check for Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank_full.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.0 Exploratory Data Analysis (EDA)** ##\n",
    "\n",
    "*Focus on understanding feature distributions, relationships, and potential data preprocessing needs.*\n",
    "\n",
    "**3.1 Univariate Analysis**\n",
    "\n",
    "*Examine the distribution of numerical variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(bank_full['age'], bins=20, kde=True)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import seaborn as sns\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# # List of numerical columns to visualize\n",
    "# numerical_columns = ['balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# for column in numerical_columns:\n",
    "#     # Histogram\n",
    "#     sns.histplot(bank_full[column], bins=20, kde=True)\n",
    "#     plt.title(f\"{column.capitalize()} Distribution\")\n",
    "#     plt.xlabel(column.capitalize())\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Boxplot\n",
    "#     sns.boxplot(x=bank_full[column])\n",
    "#     plt.title(f\"{column.capitalize()} Boxplot\")\n",
    "#     plt.xlabel(column.capitalize())\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analyze categorical variables using bar plots:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Updated list of categorical columns\n",
    "# categorical_columns = ['job', 'marital', 'education', 'default', 'housing', \n",
    "#                        'loan', 'contact', 'month', 'poutcome', 'y']\n",
    "\n",
    "# # Visualize the distributions\n",
    "# for column in categorical_columns:\n",
    "#     sns.countplot(data=bank_full, x=column, order=bank_full[column].value_counts().index)\n",
    "#     plt.title(f\"{column.capitalize()} Distribution\")\n",
    "#     plt.xlabel(column.capitalize())\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility if needed\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical variables excluding the target variable\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', \n",
    "                       'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Loop through each categorical variable and plot\n",
    "for column in categorical_columns:\n",
    "    sns.countplot(x=column, hue='y', data=bank_full, order=bank_full[column].value_counts().index)\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "    plt.title(f\"{column.capitalize()} vs Subscription\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation for numerical variables:\n",
    "corr = bank_full[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.0: Answering Business questions** ##\n",
    "\n",
    "**1. Which demographic factors (e.g., age, job, marital status, education) most influence the likelihood of subscribing to a term deposit?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for job vs subscription\n",
    "job_subscription = bank_full.groupby(['job', 'y']).size().unstack().fillna(0)\n",
    "job_subscription.plot(kind='pie', y='yes', autopct='%1.1f%%', legend=False, figsize=(8, 6), title=\"Job vs Subscription (Yes)\")\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for marital vs subscription\n",
    "marital_subscription = bank_full.groupby(['marital', 'y']).size().unstack().fillna(0)\n",
    "marital_subscription.plot(kind='pie', y='yes', autopct='%1.1f%%', legend=False, figsize=(8, 6), title=\"Marital Status vs Subscription (Yes)\")\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for education vs subscription\n",
    "education_subscription = bank_full.groupby(['education', 'y']).size().unstack().fillna(0)\n",
    "education_subscription.plot(kind='pie', y='yes', autopct='%1.1f%%', legend=False, figsize=(8, 6), title=\"Education vs Subscription (Yes)\")\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How does prior engagement with the bank (e.g., previous campaigns or contact history) impact a client’s decision to subscribe?**\n",
    "\n",
    "*Bar Plot for Average Engagement Metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average days since last contact grouped by subscription status\n",
    "pdays_mean = bank_full.groupby('y')['pdays'].mean()\n",
    "\n",
    "plt.bar(pdays_mean.index, pdays_mean, color=['lightblue', 'lightgreen'])\n",
    "plt.title(\"Average Days Since Last Contact by Subscription Status\")\n",
    "plt.ylabel(\"Average Days Since Last Contact\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n",
    "\n",
    "# Average number of previous contacts grouped by subscription status\n",
    "previous_mean = bank_full.groupby('y')['previous'].mean()\n",
    "\n",
    "plt.bar(previous_mean.index, previous_mean, color=['lightcoral', 'lightseagreen'])\n",
    "plt.title(\"Average Number of Previous Contacts by Subscription Status\")\n",
    "plt.ylabel(\"Average Number of Previous Contacts\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Violin Plot for Detailed Distributions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# Violin plot for days since last contact\n",
    "sns.violinplot(x='y', y='pdays', data=bank_full, palette=\"pastel\", split=True)\n",
    "plt.title(\"Distribution of Days Since Last Contact by Subscription Status\")\n",
    "plt.ylabel(\"Days Since Last Contact\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for number of previous contacts\n",
    "sns.violinplot(x='y', y='previous', data=bank_full, palette=\"muted\", split=True)\n",
    "plt.title(\"Distribution of Previous Contacts by Subscription Status\")\n",
    "plt.ylabel(\"Number of Previous Contacts\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the effect of financial indicators (e.g., balance, loan status, housing loan status) on subscription likelihood?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean balance for each subscription status\n",
    "balance_mean = bank_full.groupby('y')['balance'].mean()\n",
    "\n",
    "# Pie chart\n",
    "plt.pie(balance_mean, labels=balance_mean.index, autopct='%1.1f%%', colors=['skyblue', 'lightgreen'], startangle=140)\n",
    "plt.title(\"Proportion of Average Balance by Subscription Status\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_columns = ['loan', 'housing']\n",
    "\n",
    "for column in financial_columns:\n",
    "    sns.countplot(x=column, hue='y', data=bank_full)\n",
    "    plt.title(f\"{column.capitalize()} Loan Status vs Subscription\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(f\"{column.capitalize()} Loan Status\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Are there specific time-related patterns (e.g., month or day of contact) that correlate with successful subscriptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='month', hue='y', data=bank_full, order=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\n",
    "plt.title(\"Month vs Subscription\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='day', hue='y', data=bank_full)\n",
    "plt.title(\"Day of Contact vs Subscription\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Day of Contact\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Can the model help identify high-value clients, enabling the marketing team to prioritize resources effectively?**\n",
    "\n",
    "*Combination of Key Factors (Balance and Age)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='balance', y='age', hue='y', data=bank_full)\n",
    "plt.title(\"Balance vs Age by Subscription Status\")\n",
    "plt.xlabel(\"Balance (€)\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.legend(title=\"Subscription Status\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='y', y='duration', data=bank_full)\n",
    "plt.title(\"Duration of Last Contact by Subscription Status\")\n",
    "plt.ylabel(\"Duration (seconds)\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='y', y='campaign', data=bank_full)\n",
    "plt.title(\"Number of Contacts in Campaign by Subscription Status\")\n",
    "plt.ylabel(\"Number of Contacts\")\n",
    "plt.xlabel(\"Subscription Status (y)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.0: Testing Hypothesis** ##\n",
    "\n",
    "**Null Hypothesis (H₀):**\n",
    "\n",
    "*There is no statistically significant relationship between the features provided (e.g., demographic, financial, and campaign-specific attributes) and the likelihood of a client subscribing to a term deposit.*\n",
    "\n",
    "**Alternate Hypothesis (H₁):**\n",
    "\n",
    "*There is a statistically significant relationship between the features provided (e.g., demographic, financial, and campaign-specific attributes) and the likelihood of a client subscribing to a term deposit.*\n",
    "\n",
    "**Feature Importance (Statistical Tests);**\n",
    "\n",
    "*a. Chi-Square Test (Categorical Variables)*\n",
    "\n",
    "*Objective: Evaluate whether there is a significant relationship between categorical features and the target variable y.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    contingency_table = pd.crosstab(bank_full[column], bank_full['y'])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    print(f\"{column}: p-value = {p}\")\n",
    "    if p < 0.05:\n",
    "        print(f\"  Significant relationship with y (reject H₀)\")\n",
    "    else:\n",
    "        print(f\"  No significant relationship with y (fail to reject H₀)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*b. ANOVA (Numerical Variables)*\n",
    "\n",
    "*Objective: Test whether the mean of numerical features differs significantly between the yes and no groups of y.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "numerical_columns = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    group_yes = bank_full[bank_full['y'] == 'yes'][column]\n",
    "    group_no = bank_full[bank_full['y'] == 'no'][column]\n",
    "    stat, p = f_oneway(group_yes, group_no)\n",
    "    print(f\"{column}: p-value = {p}\")\n",
    "    if p < 0.05:\n",
    "        print(f\"  Significant difference (reject H₀)\")\n",
    "    else:\n",
    "        print(f\"  No significant difference (fail to reject H₀)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPARATION** ##\n",
    "\n",
    "*Data Cleaning- removing duplicates, handling missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values in the data\n",
    "bank_full.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Observation** ##\n",
    "\n",
    "*'duration':*\n",
    "\n",
    "*Highly correlated with y but causes data leakage. Exclude it during training.*\n",
    "\n",
    "*The variable pdays represents the number of days since a client was last contacted during a previous campaign.*\n",
    "\n",
    "*When pdays = -1, it means the client was not contacted before. This is important because it tells us whether a client is new to the bank's campaigns or has been engaged before.*\n",
    "\n",
    "*To understand the impact of prior contact on subscription likelihood, we need to analyze pdays in two parts:*\n",
    "\n",
    "*Clients with pdays = -1 (not contacted before).*\n",
    "\n",
    "*Clients with pdays > -1 (contacted before)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full.drop(columns=['duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into input(X) and target(y) features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = bank_full.drop('y', axis=1)  # Features: all columns except the target\n",
    "y = bank_full['y']              # Target: the 'y' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The variable pdays represents the number of days since a client was last contacted during a previous campaign.\n",
    "\n",
    "When pdays = -1, it means the client was not contacted before. This is important because it tells us whether a client is new to the bank's campaigns or has been engaged before.\n",
    "To understand the impact of prior contact on subscription likelihood, we need to analyze pdays in two parts:\n",
    "Clients with pdays = -1 (not contacted before).\n",
    "Clients with pdays > -1 (contacted before)\n",
    "\n",
    "By separating these groups, we can see if prior engagement with the client makes a difference in their decision to subscribe to a term deposit. For example, it might reveal that clients who have been contacted in the past are more likely to subscribe\n",
    "\n",
    "Handling pdays;\n",
    "\n",
    "Create a New Feature: was_contacted_before\n",
    "\n",
    "Convert pdays into a binary indicator (1 for contacted before, 0 for not contacted) to capture the essence of whether a client was previously contacted.\n",
    "\n",
    "Retain Non-Negative pdays Values for Those Contacted\n",
    "\n",
    "Replace pdays = -1 with 0 or NaN to avoid skewing the data distribution during numerical transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pdays into a binary indicator (1 for contacted before, 0 for not contacted)\n",
    "X['was_contacted_before'] = (X['pdays'] != -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace pdays = -1 with 0 or NaN to avoid skewing the data distribution during numerical transformations\n",
    "X['pdays'] = X['pdays'].apply(lambda x: 0 if x == -1 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify changes\n",
    "print(X[['pdays', 'was_contacted_before']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the numeric columns\n",
    "numeric_cols = X.select_dtypes(include='number').columns\n",
    "\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the categorical columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into training and evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using train test split to split the data with test size of 0.2\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding\n",
    "\n",
    "*Normalization & Scaling*\n",
    "\n",
    "#### 4.1 Creating a Pipeline to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "\n",
    "# Numeric columns (including 'pdays' and 'was_contacted_before')\n",
    "numeric_cols = X_train.select_dtypes(include='number').columns\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns\n",
    "\n",
    "# Define the pipeline for numerical features\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
    "    ('scaler', RobustScaler())                       # Use RobustScaler to handle outliers\n",
    "])\n",
    "\n",
    "# Define the pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))        # One-hot encode categorical variables\n",
    "])\n",
    "\n",
    "# Combine pipelines into a preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical_transformations', numeric_pipeline, numeric_cols),\n",
    "    ('categorical_transformations', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Confirm the setup of the preprocessor\n",
    "print(preprocessor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Label/Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training target and transform both train and test targets\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Verify the encoding\n",
    "print(\"Classes:\", label_encoder.classes_)\n",
    "print(\"Encoded y_train:\", y_train_encoded[:5])\n",
    "print(\"Encoded y_test:\", y_test_encoded[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Modeling\n",
    "\n",
    "#### 5.1 ML Pipeline(Unbalanced Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# import pandas as pd\n",
    "\n",
    "# List of models to train\n",
    "models = [\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('SVC', SVC(random_state=42, probability=True)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# Define metrics dataframe\n",
    "unbalanced_metrics = pd.DataFrame(columns=['Model Name', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Loop through models\n",
    "for model_name, classifier in models:\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate classification metrics\n",
    "    metrics = classification_report(y_test_encoded, y_pred, output_dict=True)\n",
    "    \n",
    "    # Extract key metrics\n",
    "    accuracy = metrics['accuracy']\n",
    "    precision = metrics['weighted avg']['precision']\n",
    "    recall = metrics['weighted avg']['recall']\n",
    "    f1_score = metrics['weighted avg']['f1-score']\n",
    "    \n",
    "    # Append results to metrics dataframe\n",
    "    unbalanced_metrics.loc[len(unbalanced_metrics)] = [model_name, accuracy, precision, recall, f1_score]\n",
    "\n",
    "# Display metrics\n",
    "print(unbalanced_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Evaluation \n",
    "\n",
    "#### 6.1 Train and compare data(Random Oversampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import pandas as pd\n",
    "\n",
    "# Oversampling to balance the dataset\n",
    "sampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "# Initialize a dataframe to store the evaluation metrics\n",
    "balanced_metrics = pd.DataFrame(columns=['Model Name', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Loop through the models for evaluation\n",
    "for model_name, classifier in models:\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier),\n",
    "    ])\n",
    "\n",
    "    # Train the pipeline with the oversampled dataset\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing dataset\n",
    "    y_pred_resampled = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate classification metrics\n",
    "    metrics = classification_report(y_test_encoded, y_pred_resampled, output_dict=True)\n",
    "    \n",
    "    # Extract key metrics\n",
    "    accuracy = metrics['accuracy']\n",
    "    precision = metrics['weighted avg']['precision']\n",
    "    recall = metrics['weighted avg']['recall']\n",
    "    f1_score = metrics['weighted avg']['f1-score']\n",
    "    \n",
    "    # Append the results to the balanced_metrics dataframe\n",
    "    balanced_metrics.loc[len(balanced_metrics)] = [model_name, accuracy, precision, recall, f1_score]\n",
    "\n",
    "# Display the results\n",
    "print(balanced_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using over sampling method on the dataset to balance your dataset\n",
    "sampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled,y_train_resampled = sampler.fit_resample(X_train,y_train_encoded)\n",
    "\n",
    "balanced_metrics = pd.DataFrame(columns=['Model_name','Accuracy','Precision','Recall','F1_score'])\n",
    "# looping over the models\n",
    "for model_name,classifier in models:\n",
    "    pipeline=Pipeline(steps=[\n",
    "        ('preprocessor',preprocessor),\n",
    "        ('classifier',classifier),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train_resampled,y_train_resampled)\n",
    "    \n",
    "    # predicting on the testing dataset\n",
    "    oversampler_y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    balanced_result = classification_report(y_test_encoded,oversampler_y_pred ,output_dict=True)\n",
    "   \n",
    "    accuracy = balanced_result['accuracy']\n",
    "    precision = balanced_result['weighted avg']['precision']\n",
    "    recall = balanced_result['weighted avg']['recall']\n",
    "    f1_score = balanced_result['weighted avg']['f1-score']\n",
    "    balanced_metrics.loc[len(balanced_metrics)]=[model_name,accuracy,recall,precision,f1_score]\n",
    "\n",
    "balanced_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Train and balance dataset on SMote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pipeline ={}\n",
    "# smote_df = pd.DataFrame(columns=['Model_name','Accuracy','Precision','Recall','F1_score'])\n",
    "# for model_name,classifier in models:\n",
    "#     pipeline=imbpipeline(steps=[\n",
    "#         ('preprocessor',preprocessor),\n",
    "#         ('smote',SMOTE(random_state=42)),\n",
    "#         ('classifier',classifier),\n",
    "#     ])\n",
    "\n",
    "#     pipeline.fit(X_train,y_train_encoded)\n",
    "    \n",
    "#     # predicting on the testing dataset\n",
    "#     smote_y_pred = pipeline.predict(X_test)\n",
    "#     all_pipeline[model_name] = pipeline\n",
    "#     smote_dict = classification_report(y_test_encoded,smote_y_pred,output_dict=True)\n",
    "   \n",
    "#     accuracy = smote_dict['accuracy']\n",
    "#     precision = smote_dict['weighted avg']['precision']\n",
    "#     recall = smote_dict['weighted avg']['recall']\n",
    "#     f1_score = smote_dict['weighted avg']['f1-score']\n",
    "#     smote_df.loc[len(smote_df)]=[model_name,accuracy,recall,precision,f1_score]\n",
    "\n",
    "# smote_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Train Data on Feature Importance and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using kbest to select the best features\n",
    "# selection = SelectKBest(mutual_info_classif,k=10)\n",
    "\n",
    "# fi_smote_df = pd.DataFrame(columns=['Model_name','Accuracy','Precision','Recall','F1_score'])\n",
    "\n",
    "# all_pipeline ={}\n",
    "# for model_name,classifier in models:\n",
    "#     pipeline=imbpipeline(steps=[\n",
    "#         ('preprocessor',preprocessor),\n",
    "#         ('smote',SMOTE(random_state=42)),\n",
    "#         ('feature_selection',selection),\n",
    "#         ('classifier',classifier),\n",
    "        \n",
    "#     ])\n",
    "\n",
    "#     pipeline.fit(X_train,y_train_encoded)\n",
    "\n",
    "#     fi_y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#     all_pipeline[model_name] = pipeline\n",
    "    \n",
    "#     fi_smote_dict = classification_report(y_test_encoded,fi_y_pred,output_dict=True)\n",
    "   \n",
    "#     accuracy = fi_smote_dict['accuracy']\n",
    "#     precision = fi_smote_dict['weighted avg']['precision']\n",
    "#     recall = fi_smote_dict['weighted avg']['recall']\n",
    "#     f1_score = fi_smote_dict['weighted avg']['f1-score']\n",
    "#     fi_smote_df.loc[len(fi_smote_df)]=[model_name,accuracy,recall,precision,f1_score]\n",
    "\n",
    "# fi_smote_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Visualize ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ROC curve\n",
    "# fig,ax = plt.subplots(figsize=(8,8))\n",
    "# roc_auc_curve_data = {}\n",
    "# for model_name,classifier in models:\n",
    "#     pipeline=imbpipeline(steps=[\n",
    "#         ('preprocessor',preprocessor),\n",
    "#         ('smote',SMOTE(random_state=42)),\n",
    "#         ('feature_selection',selection),\n",
    "#         ('classifier',classifier),\n",
    "        \n",
    "#     ])\n",
    "#     # fitting our pipeline with train data\n",
    "#     pipeline.fit(X_train,y_train_encoded)\n",
    "\n",
    "#     y_score = pipeline.predict_proba(X_test)[:,1]\n",
    "#     fpr,tpr,threshold= roc_curve(y_test_encoded,y_score)\n",
    "#     roc_auc = auc(fpr,tpr)\n",
    "\n",
    "#     roc_auc_curve_df = pd.DataFrame({'false positive rate':fpr,'True positive rate':tpr,'Threshold':threshold})\n",
    "#     roc_auc_curve_data[model_name] = roc_auc_curve_df\n",
    "\n",
    "#     ax.plot(fpr,tpr,label =f'{model_name}(AUC={roc_auc:.2f})')\n",
    "#     ax.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristics ROC Curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- - From the curve we can see that gradient boosting classifier covered the most area with an auc of 0.85, it is the best performing model so far -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using the best performing pipelime to predict on the data\n",
    "# gradient_pipeline = all_pipeline['Gradient Boosting']\n",
    "\n",
    "# grad_y_pred =gradient_pipeline.predict(X_test)\n",
    "# matrix = confusion_matrix(y_test_encoded, grad_y_pred)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using the best performing pipelime to predict on the data\n",
    "# random_pipeline = all_pipeline['Random Forest']\n",
    "\n",
    "# ran_y_pred =random_pipeline.predict(X_test)\n",
    "# matrix = confusion_matrix(y_test_encoded, ran_y_pred)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naives_pipeline =all_pipeline['Naives_Bay']\n",
    "\n",
    "# naives_y_pred =naives_pipeline.predict(X_test)\n",
    "# nav_matrix = confusion_matrix(y_test_encoded, naives_y_pred)\n",
    "# nav_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # printing the confusion matrix\n",
    "# sns.heatmap(data=matrix,annot=True,fmt='d',cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the fpr,tpr and threshold \n",
    "# roc_auc_curve_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting threshold and using the threshold to predict on X_test\n",
    "# threshold = 0.11\n",
    "# y_pred_proba = gradient_pipeline.predict_proba(X_test)[:, 1]\n",
    "# binary_prediction = (y_pred_proba > threshold)\n",
    "# threshold_matrix = confusion_matrix(y_test_encoded,binary_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # printing confusion matrix after setting the threshold\n",
    "# sns.heatmap(data=threshold_matrix,annot=True,fmt='d',cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Hyperparameter Tuning\n",
    "\n",
    "*Create a dictionary of tuning parameters (hyperparameters)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting the parameters (gradient pipeline)\n",
    "# params_grid = {\n",
    "#     'feature_selection__k': [5, 10, 15],  \n",
    "#     'classifier__n_estimators': [5, 10, 15],\n",
    "#     'classifier__max_depth': [None, 10, 20],\n",
    "#     'classifier__min_samples_split': [2, 5, 10],\n",
    "# }\n",
    "\n",
    "# searcher1 = GridSearchCV(\n",
    "#     gradient_pipeline, \n",
    "#     param_grid=params_grid, \n",
    "#     cv=5, scoring='f1'\n",
    "#     )\n",
    "# # fitting the searcher with train data\n",
    "# searcher1.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform hyper paramter tuning on the naives bay model\n",
    "# params_grid = {\n",
    "#     'classifier__priors': [None],  # Add appropriate values if needed\n",
    "#     'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "# }\n",
    "\n",
    "# searcher_n = GridSearchCV(\n",
    "#     naives_pipeline, \n",
    "#     param_grid=params_grid, \n",
    "#     cv=5, scoring='f1'\n",
    "#     )\n",
    "# # fitting the searcher with train data\n",
    "# searcher_n.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting the parameters with the random forest pipeline\n",
    "# params_grid = {\n",
    "#     'feature_selection__k': [5, 10, 15],  \n",
    "#     'classifier__n_estimators': [5, 10, 15],\n",
    "#     'classifier__max_depth': [None, 10, 20],\n",
    "#     'classifier__min_samples_split': [2, 5, 10],\n",
    "# }\n",
    "\n",
    "# searcher2 = GridSearchCV(\n",
    "#     random_pipeline, \n",
    "#     param_grid=params_grid, \n",
    "#     cv=5, scoring='f1'\n",
    "#     )\n",
    "# # fitting the searcher with train data\n",
    "# searcher2.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the results of the tuned data in a dataframe\n",
    "# search_history = pd.DataFrame(searcher.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the best parameter used for gradient pipeline\n",
    "# best = searcher1.best_params_\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the best parameter used for naives  bay\n",
    "# best_params = searcher_n.best_params_\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the best parameter used for random\n",
    "# best_parameters = searcher2.best_params_\n",
    "# best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.5.1 Retrain model with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "# random_pipeline.set_params(**best_parameters)\n",
    "# random_pipeline.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gradient\n",
    "# gradient_pipeline.set_params(**best)\n",
    "# gradient_pipeline.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrain the model with the best parameters naives\n",
    "# naives_pipeline.set_params(**best_params)\n",
    "# naives_pipeline.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 **Business Impact & Assessment** ##\n",
    "\n",
    "Our team used machine learning to predict customer churn for a telecommunications company, and achieved an accuracy of 0.82 and a lift of 2.28 with our Gradient Boosting model. The key metrics and findings of our model are:\n",
    "\n",
    "**Precision:**\n",
    "*0.76*\n",
    "\n",
    "**Recall:** \n",
    "*0.71*\n",
    "\n",
    "**Specificity:** \n",
    "*0.87*\n",
    "\n",
    "**F1 score:** \n",
    "*0.73*\n",
    "\n",
    "**Gain:**\n",
    "*0.71*\n",
    "\n",
    "**The confusion matrix of our model on the testing set is:**\n",
    "\n",
    "**Predicted Churn\tPredicted Stay**\n",
    "\n",
    "**Actual Churn**\t*355 (TP)\t144 (FN)*\n",
    "\n",
    "**Actual Stay**\t    *112 (FP)\t789 (TN)*\n",
    "\n",
    "Our model correctly identified 76% of the customers who churned, and captured 71% of the total churners in the testing set. This means that our model was more than twice as likely to find a churner than a random guess, and could help the company reduce the number of missed opportunities and revenue losses.\n",
    "\n",
    "We recommend that the company use our model to identify the customers who are at risk of churn, and implement retention strategies based on the insights derived from the data analysis, such as offering discounts, benefits, or personalized services to these customers. 🙏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0 Testing on unknown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = gradient_pipeline.predict(df_test)\n",
    "# prediction=LabelEncoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = random_pipeline.predict(df_test)\n",
    "# pred = LabelEncoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['churn'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['Churn']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.0 Model Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "#os.makedirs('./models/')\n",
    "#joblib.dump(gradient_pipeline,'./models/gradient_pipeline.joblib')\n",
    "#joblib.dump(OneHotEncoder,'./models/encoder.joblib')\n",
    "#joblib.dump(LabelEncoder,'./models/encoderl.joblib')\n",
    "#joblib.dump(random_pipeline,'./models/random_pipeline.joblib')\n",
    "#joblib.dump(naives_pipeline,'./models/naives_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Conclusions and Recommendations\n",
    "\n",
    "In conclusion, the development and evaluation of the classification model using a gradient pipeline have yielded insightful results. The gradient pipeline, which incorporates feature selection, sampling techniques, and hyperparameter tuning, has contributed to the model's ability to capture complex patterns in the data. Through rigorous testing on an independent test set, we have assessed the model's performance using key classification metrics.\n",
    "\n",
    "The evaluation metrics, including accuracy, precision, recall, F1 score, and area under the ROC curve, provide a comprehensive understanding of the model's strengths and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
